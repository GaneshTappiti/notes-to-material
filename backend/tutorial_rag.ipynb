{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a253554",
   "metadata": {},
   "source": [
    "# Local RAG Pipeline Tutorial (Ingestion → Embeddings → Retrieval → Generation)\n",
    "\n",
    "This notebook demonstrates a minimal **local-first** pipeline using the same building blocks wired into the FastAPI backend:\n",
    "1. Ingest a PDF with **PyMuPDF** + OCR fallback (**Tesseract**).\n",
    "2. Chunk & embed pages with **Gemini Embeddings** (or a local fallback) stored in **Chroma**.\n",
    "3. Retrieve top-*k* chunks via cosine similarity.\n",
    "4. Run a structured RAG prompt against **Gemini** (or stub) and validate JSON.\n",
    "5. Show how these steps map to backend endpoints (/api/uploads, /api/jobs, etc.).\n",
    "\n",
    "> If you don't set `GOOGLE_API_KEY`, the notebook will auto-fallback to deterministic pseudo-embeddings + a stub generator so you can still exercise the flow offline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffe24b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Install runtime deps if running standalone.\n",
    "# You can skip this cell if you've already pip installed in the environment.\n",
    "# !pip install PyMuPDF pytesseract Pillow chromadb faiss-cpu jsonschema google-generativeai tenacity\n",
    "import os, math, json, hashlib, random\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "try:\n",
    "    import fitz  # PyMuPDF\n",
    "except ImportError as e:\n",
    "    raise RuntimeError('PyMuPDF not installed. Run the pip install cell.') from e\n",
    "\n",
    "try:\n",
    "    import pytesseract  # OCR fallback\n",
    "except ImportError:\n",
    "    pytesseract = None  # OCR optional\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from jsonschema import validate as json_validate\n",
    "from jsonschema import ValidationError\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY', '')\n",
    "print('Gemini key detected?' , bool(GOOGLE_API_KEY))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08daab2a",
   "metadata": {},
   "source": [
    "## 1. Ingestion (extract text + images + OCR fallback)\n",
    "Mirrors backend/app/services/pdf_extract.py with light adjustments for notebook execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2929a021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pages(filepath: str):\n",
    "    doc = fitz.open(filepath)\n",
    "    pages = []\n",
    "    for i in range(doc.page_count):\n",
    "        page = doc.load_page(i)\n",
    "        text = page.get_text('text').strip()\n",
    "        images_meta = page.get_images(full=True)\n",
    "        extracted_images = []\n",
    "        for img in images_meta:\n",
    "            xref = img[0]\n",
    "            pix = fitz.Pixmap(doc, xref)\n",
    "            if pix.n - pix.alpha > 3:  # convert CMYK\n",
    "                pix = fitz.Pixmap(fitz.csRGB, pix)\n",
    "            img_bytes = pix.tobytes('png')\n",
    "            extracted_images.append({'page': i+1, 'image_hex': img_bytes.hex()})\n",
    "        if not text:  # OCR fallback\n",
    "            if pytesseract is not None:\n",
    "                pix = page.get_pixmap(dpi=200)\n",
    "                img = Image.open(BytesIO(pix.tobytes('png')))\n",
    "                ocr_text = pytesseract.image_to_string(img)\n",
    "                text = ocr_text.strip()\n",
    "        pages.append({'page_no': i+1, 'text': text, 'images': extracted_images})\n",
    "    return pages\n",
    "\n",
    "# SAMPLE INPUT: point to a local small PDF (replace this path)\n",
    "SAMPLE_PDF = 'sample.pdf'  # Place a small PDF in the working dir.\n",
    "if not os.path.exists(SAMPLE_PDF):\n",
    "    # create a tiny one-page PDF if missing (blank)\n",
    "    doc = fitz.open()\n",
    "    page = doc.new_page()\n",
    "    page.insert_text((72,72), 'Demo PDF content about photosynthesis and energy conversion.')\n",
    "    doc.save(SAMPLE_PDF)\n",
    "pages = extract_pages(SAMPLE_PDF)\n",
    "len(pages), pages[0]['text'][:80]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06165c9",
   "metadata": {},
   "source": [
    "## 2. Chunking & Embeddings\n",
    "We'll treat each page as a chunk. For short pages you could merge neighbors.\n",
    "If a Gemini API key is present we use the real embedding endpoint via `google-generativeai`; else we use a deterministic pseudo-embedding (hash-based)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73a7649",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.generativeai as genai\n",
    "    if GOOGLE_API_KEY:\n",
    "        genai.configure(api_key=GOOGLE_API_KEY)\n",
    "except ImportError:\n",
    "    genai = None\n",
    "\n",
    "def embed_texts(texts: List[str]):\n",
    "    if genai and GOOGLE_API_KEY:\n",
    "        # Gemini embedding model name may evolve; adjust per docs.\n",
    "        model = 'text-embedding-004'  # or gemini-embedding-001 depending on availability\n",
    "        out = []\n",
    "        for t in texts:\n",
    "            resp = genai.embed_content(model=model, content=t)\n",
    "            out.append(resp['embedding'])\n",
    "        return out\n",
    "    # Fallback: deterministic pseudo-embedding (NOT for production)\n",
    "    out = []\n",
    "    for t in texts:\n",
    "        h = hashlib.sha256(t.encode('utf-8')).digest()[:128]  # 128 bytes\n",
    "        vec = [b/255.0 for b in h]\n",
    "        out.append(vec)\n",
    "    return out\n",
    "\n",
    "page_texts = [p['text'] or '' for p in pages]\n",
    "embeddings = embed_texts(page_texts)\n",
    "len(embeddings), len(embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb70b53",
   "metadata": {},
   "source": [
    "## 3. Store in Chroma & Retrieval\n",
    "Using an ephemeral in-memory Chroma collection (persist directory optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbb36b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = chromadb.Client()\n",
    "collection = client.get_or_create_collection('notes')\n",
    "# Upsert pages\n",
    "for idx, (p, emb) in enumerate(zip(pages, embeddings)):\n",
    "    collection.upsert(ids=[f'page-{idx+1}'], embeddings=[emb], metadatas=[{'page_no': p['page_no']}], documents=[p['text']])\n",
    "collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2dae2a",
   "metadata": {},
   "source": [
    "### Similarity Search Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f386efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query: str, k: int = 3):\n",
    "    q_emb = embed_texts([query])[0]\n",
    "    res = collection.query(query_embeddings=[q_emb], n_results=k)\n",
    "    hits = []\n",
    "    for i, doc in enumerate(res['documents'][0]):\n",
    "        hits.append({\n",
    "            'id': res['ids'][0][i],\n",
    "            'text': doc,\n",
    "            'metadata': res['metadatas'][0][i],\n",
    "            'distance': res['distances'][0][i] if 'distances' in res else None\n",
    "        })\n",
    "    return hits\n",
    "\n",
    "retrieve('photosynthesis energy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6770fedc",
   "metadata": {},
   "source": [
    "## 4. Structured RAG Generation\n",
    "We craft a strict JSON instruction. If Gemini not available, stub returns an example structure.\n",
    "Schema (simplified):\n",
    "```json\n",
    "{ 'items': [ { 'question': str, 'answer': str, 'page_references': [str] } ] }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b077f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA = {\n",
    "    'type': 'object',\n",
    "    'properties': {\n",
    "        'items': {\n",
    "            'type': 'array',\n",
    "            'items': {\n",
    "                'type': 'object',\n",
    "                'properties': {\n",
    "                    'question': {'type': 'string'},\n",
    "                    'answer': {'type': 'string'},\n",
    "                    'page_references': { 'type': 'array', 'items': {'type': 'string'} }\n",
    "                },\n",
    "                'required': ['question','answer','page_references']\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'required': ['items']\n",
    "}\n",
    "\n",
    "def rag_generate(question: str, k: int = 3):\n",
    "    ctx_hits = retrieve(question, k=k)\n",
    "    ctx_block = '\n",
    "\n",
    "'.join([f\n",
    " for h in ctx_hits])\n",
    "    if genai and GOOGLE_API_KEY:\n",
    "        instruction = (\n",
    "            'You are a strict academic assistant. Use ONLY the provided context. '\n",
    "            'Return compact JSON with key \"items\" (array). Each item: question, answer, page_references. '\n",
    "            'If insufficient info, answer with an empty items array.'\n",
    "        )\n",
    "        prompt = f\n",
    "        model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "        resp = model.generate_content(prompt)\n",
    "        text = resp.text\n",
    "    else:\n",
    "        # Stub JSON for offline demo\n",
    "        refs = [f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc168a56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c44e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a71a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e147df5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc99e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3e9b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad797e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafe21fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0459e6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65212f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1872fe96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afa50e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60f609b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb259f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058c6288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17e297c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd911e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
